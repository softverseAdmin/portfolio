User-agent: *
Allow: /

# Sitemap
# robots.txt for DevOps Enginer Portfolio
# Allow all crawlers to access all content

User-agent: *
Allow: /

# Sitemap location
Sitemap: https://www.devopsenginer.com/sitemap.xml

# Specific crawling preferences
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

User-agent: DuckDuckBot
Allow: /

# Block access to sensitive files
Disallow: /api/
Disallow: /_next/
Disallow: /admin/
Disallow: /.env
Disallow: /package.json
Disallow: /node_modules/

# Allow specific important files
Allow: /robots.txt
Allow: /sitemap.xml
Allow: /ads.txt
Allow: /site.webmanifest

# Crawl delay (optional)
Crawl-delay: 1

# Host preference
Host: https://www.devopsenginer.com

# Crawl-delay for better server performance
Crawl-delay: 1

# Allow all major search engines
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

# Disallow admin areas (future use)
Disallow: /admin/
Disallow: /api/private/
